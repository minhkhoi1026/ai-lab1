using JuMP, Ipopt

function tensorform(ğ’«::SimpleGame)
    â„, ğ’œ, R =ğ’«.â„, ğ’«.ğ’œ, ğ’«.R
    â„â€² = eachindex(â„)
    ğ’œâ€² = [eachindex(ğ’œ[i]) for i in â„]
    Râ€² = [R(a) for a in joint(ğ’œ)]
    return â„â€², ğ’œâ€², Râ€²
end

function solve_nash(ğ’«::SimpleGame)
    â„, ğ’œ, R = tensorform(ğ’«)
    model = Model(Ipopt.Optimizer)
    set_silent(model)
    @variable(model, U[â„])
    @variable(model, Ï€[i=â„,ğ’œ[i]] â‰¥ 0)
    @NLobjective(model, Min, 
        sum(U[i] - sum(prod(Ï€[j,a[j]] for j in â„) * R[y][i]
            for (y,a) in enumerate(joint(ğ’œ))) for i in â„))
    @NLconstraint(model, [i=â„, ai=ğ’œ[i]],
        U[i] â‰¥ sum(
            prod(j==i ? (a[j]==ai ? 1.0 : 0.0) : Ï€[j,a[j]] for j in â„)
            *R[y][i] for (y,a) in enumerate(joint(ğ’œ))))
    @constraint(model, [i=â„], sum(Ï€[i,ai] for ai in ğ’œ[i]) == 1)
    optimize!(model)
    Ï€iâ€²(i) = SimpleGamePolicy(ğ’«.ğ’œ[i][ai] => value(Ï€[i,ai]) for ai in ğ’œ[i])
    return [Ï€iâ€²(i) for i in â„]
end

function print_nash(Ï€)
    for Ï€i in Ï€
        println("Agent")
        for i in Ï€i.p
            print(i.first)
            print(" : ")
            println(i.second)
        end
        println()
    end
end